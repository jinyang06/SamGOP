[07/02 15:52:47] detectron2 INFO: Rank of current process: 0. World size: 1
[07/02 15:52:48] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]
numpy                            1.24.4
detectron2                       0.6 @/data1/jinyang/SamGOP/detectron2/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.6
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.9.0 @/data1/jinyang/anaconda3/envs/samgop/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3090 Ti (arch=8.6)
Driver version                   535.161.07
CUDA_HOME                        /usr/local/cuda
Pillow                           9.3.0
torchvision                      0.10.0 @/data1/jinyang/anaconda3/envs/samgop/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/02 15:52:48] detectron2 INFO: Command line arguments: Namespace(EVAL_FLAG=1, config_file='/data1/jinyang/SamGOP/configs/coco/instance-segmentation/maskdino_R50_bs16_50ep_3s.yaml', dist_url='tcp://127.0.0.1:8137', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '2', 'SOLVER.BASE_LR', '0.0001'], resume=False)
[07/02 15:52:48] detectron2 INFO: Contents of args.config_file=/data1/jinyang/SamGOP/configs/coco/instance-segmentation/maskdino_R50_bs16_50ep_3s.yaml:
_BASE_: Base-COCO-InstanceSegmentation.yaml
MODEL:
  META_ARCHITECTURE: "MaskDINO"
  SEM_SEG_HEAD:
    NAME: "MaskDINOHead"
    IGNORE_VALUE: 255
    NUM_CLASSES: 24
    LOSS_WEIGHT: 1.0
    CONVS_DIM: 256
    MASK_DIM: 256
    NORM: "GN"
    # pixel decoder
    PIXEL_DECODER_NAME: "MaskDINOEncoder"
    DIM_FEEDFORWARD: 1024
    NUM_FEATURE_LEVELS: 3
    TOTAL_NUM_FEATURE_LEVELS: 3
    IN_FEATURES: ["res2", "res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES: ["res3", "res4", "res5"]
    COMMON_STRIDE: 4
    TRANSFORMER_ENC_LAYERS: 6
  MaskDINO:
    TRANSFORMER_DECODER_NAME: "MaskDINODecoder"
    DEEP_SUPERVISION: True
    NO_OBJECT_WEIGHT: 0.1
    CLASS_WEIGHT: 4.0
    MASK_WEIGHT: 5.0
    DICE_WEIGHT: 5.0
    BOX_WEIGHT: 5.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NUM_OBJECT_QUERIES: 300
    NHEADS: 8
    DROPOUT: 0.0
    DIM_FEEDFORWARD: 2048
    ENC_LAYERS: 0
    PRE_NORM: False
    ENFORCE_INPUT_PROJ: False
    SIZE_DIVISIBILITY: 32
    DEC_LAYERS: 9  # 9+1, 9 decoder layers, add one for the loss on learnable query
    TRAIN_NUM_POINTS: 12544
    OVERSAMPLE_RATIO: 3.0
    IMPORTANCE_SAMPLE_RATIO: 0.75
    INITIAL_PRED: True
    TWO_STAGE: True
    DN: "seg"
    DN_NUM: 100
    INITIALIZE_BOX_TYPE: "bitmask"
    TEST:
      SEMANTIC_ON: False
      INSTANCE_ON: True
      PANOPTIC_ON: False
      OVERLAP_THRESHOLD: 0.8
      OBJECT_MASK_THRESHOLD: 0.25

SOLVER:
  AMP:
    ENABLED: True
TEST:
  EVAL_PERIOD: 18
#  EVAL_FLAG: 1
[07/02 15:52:48] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_2017_val
  TRAIN:
  - coco_2017_train
Default_loading: true
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: false
  CROP:
    ENABLED: false
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  DATASET_MAPPER_NAME: coco_instance_lsj
  FORMAT: RGB
  IMAGE_SIZE: 224
  MASK_FORMAT: polygon
  MAX_SCALE: 1.0
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SCALE: 0.8
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: -1
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 0
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: MaskDINO
  MaskDINO:
    BOX_LOSS: true
    BOX_WEIGHT: 5.0
    CLASS_WEIGHT: 4.0
    COST_BOX_WEIGHT: 5.0
    COST_CLASS_WEIGHT: 4.0
    COST_DICE_WEIGHT: 5.0
    COST_GIOU_WEIGHT: 2.0
    COST_MASK_WEIGHT: 5.0
    DEC_LAYERS: 9
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 2048
    DN: seg
    DN_NOISE_SCALE: 0.4
    DN_NUM: 100
    DROPOUT: 0.0
    ENC_LAYERS: 0
    ENFORCE_INPUT_PROJ: false
    EVAL_FLAG: 1
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    IMPORTANCE_SAMPLE_RATIO: 0.75
    INITIALIZE_BOX_TYPE: bitmask
    INITIAL_PRED: true
    LEARN_TGT: false
    MASK_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_OBJECT_QUERIES: 300
    OVERSAMPLE_RATIO: 3.0
    PANO_BOX_LOSS: false
    PRED_CONV: false
    PRE_NORM: false
    SEMANTIC_CE_LOSS: false
    SIZE_DIVISIBILITY: 32
    TEST:
      INSTANCE_ON: true
      OBJECT_MASK_THRESHOLD: 0.25
      OVERLAP_THRESHOLD: 0.8
      PANOPTIC_ON: false
      PANO_TEMPERATURE: 0.06
      PANO_TRANSFORM_EVAL: true
      SEMANTIC_ON: false
      SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE: false
      TEST_FOUCUS_ON_BOX: false
    TRAIN_NUM_POINTS: 12544
    TRANSFORMER_DECODER_NAME: MaskDINODecoder
    TWO_STAGE: true
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 1
    - 1
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: basic
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES:
    - res3
    - res4
    - res5
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    DIM_FEEDFORWARD: 1024
    FEATURE_ORDER: high2low
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    MASK_DIM: 256
    NAME: MaskDINOHead
    NORM: GN
    NUM_CLASSES: 24
    NUM_FEATURE_LEVELS: 3
    PIXEL_DECODER_NAME: MaskDINOEncoder
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    TOTAL_NUM_FEATURE_LEVELS: 3
    TRANSFORMER_ENC_LAYERS: 6
    USE_DEPTHWISE_SEPARABLE_CONV: false
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: detectron2://ImageNetPretrained/torchvision/R-50.pkl
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 50000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 180500
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 327778
  - 355092
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 18
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[07/02 15:52:48] detectron2 INFO: Full config saved to ./output/config.yaml
[07/02 15:52:50] d2.engine.defaults INFO: Model:
MaskDINO(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
  )
  (sem_seg_head): MaskDINOHead(
    (pixel_decoder): MaskDINOEncoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MaskDINODecoder(
      (enc_output): Linear(in_features=256, out_features=256, bias=True)
      (enc_output_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=24, bias=True)
      (label_enc): Embedding(24, 256)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (decoder_head): DeformableTransformerDecoder(
        (layers): ModuleList(
          (0): DeformableTransformerDecoderLayerForHead(
            (cross_attn): MSDeformAttn(
              (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
              (attention_weights): Linear(in_features=256, out_features=96, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (dropout2): Dropout(p=0.0, inplace=False)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout3): Dropout(p=0.0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (dropout4): Dropout(p=0.0, inplace=False)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): DeformableTransformerDecoderLayerForHead(
            (cross_attn): MSDeformAttn(
              (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
              (attention_weights): Linear(in_features=256, out_features=96, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (dropout2): Dropout(p=0.0, inplace=False)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout3): Dropout(p=0.0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (dropout4): Dropout(p=0.0, inplace=False)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (2): DeformableTransformerDecoderLayerForHead(
            (cross_attn): MSDeformAttn(
              (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
              (attention_weights): Linear(in_features=256, out_features=96, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (dropout2): Dropout(p=0.0, inplace=False)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout3): Dropout(p=0.0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (dropout4): Dropout(p=0.0, inplace=False)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (reference_points_head): Linear(in_features=256, out_features=2, bias=True)
      (query_embed_head): Embedding(300, 512)
      (decoder): TransformerDecoder(
        (layers): ModuleList(
          (0): DeformableTransformerDecoderLayer(
            (cross_attn): MSDeformAttn(
              (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
              (attention_weights): Linear(in_features=256, out_features=96, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (dropout2): Dropout(p=0.0, inplace=False)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout3): Dropout(p=0.0, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (dropout4): Dropout(p=0.0, inplace=False)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): DeformableTransformerDecoderLayer(
            (cross_attn): MSDeformAttn(
              (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
              (attention_weights): Linear(in_features=256, out_features=96, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (dropout2): Dropout(p=0.0, inplace=False)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout3): Dropout(p=0.0, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (dropout4): Dropout(p=0.0, inplace=False)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (2): DeformableTransformerDecoderLayer(
            (cross_attn): MSDeformAttn(
              (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
              (attention_weights): Linear(in_features=256, out_features=96, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (dropout2): Dropout(p=0.0, inplace=False)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout3): Dropout(p=0.0, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (dropout4): Dropout(p=0.0, inplace=False)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (3): DeformableTransformerDecoderLayer(
            (cross_attn): MSDeformAttn(
              (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
              (attention_weights): Linear(in_features=256, out_features=96, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (dropout2): Dropout(p=0.0, inplace=False)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout3): Dropout(p=0.0, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (dropout4): Dropout(p=0.0, inplace=False)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (4): DeformableTransformerDecoderLayer(
            (cross_attn): MSDeformAttn(
              (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
              (attention_weights): Linear(in_features=256, out_features=96, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (dropout2): Dropout(p=0.0, inplace=False)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout3): Dropout(p=0.0, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (dropout4): Dropout(p=0.0, inplace=False)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (5): DeformableTransformerDecoderLayer(
            (cross_attn): MSDeformAttn(
              (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
              (attention_weights): Linear(in_features=256, out_features=96, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (dropout2): Dropout(p=0.0, inplace=False)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout3): Dropout(p=0.0, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (dropout4): Dropout(p=0.0, inplace=False)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (6): DeformableTransformerDecoderLayer(
            (cross_attn): MSDeformAttn(
              (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
              (attention_weights): Linear(in_features=256, out_features=96, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (dropout2): Dropout(p=0.0, inplace=False)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout3): Dropout(p=0.0, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (dropout4): Dropout(p=0.0, inplace=False)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (7): DeformableTransformerDecoderLayer(
            (cross_attn): MSDeformAttn(
              (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
              (attention_weights): Linear(in_features=256, out_features=96, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (dropout2): Dropout(p=0.0, inplace=False)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout3): Dropout(p=0.0, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (dropout4): Dropout(p=0.0, inplace=False)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (8): DeformableTransformerDecoderLayer(
            (cross_attn): MSDeformAttn(
              (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
              (attention_weights): Linear(in_features=256, out_features=96, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (dropout2): Dropout(p=0.0, inplace=False)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout3): Dropout(p=0.0, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (dropout4): Dropout(p=0.0, inplace=False)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (ref_point_head): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=512, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
          )
        )
        (bbox_embed): ModuleList(
          (0): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=256, bias=True)
              (1): Linear(in_features=256, out_features=256, bias=True)
              (2): Linear(in_features=256, out_features=4, bias=True)
            )
          )
          (1): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=256, bias=True)
              (1): Linear(in_features=256, out_features=256, bias=True)
              (2): Linear(in_features=256, out_features=4, bias=True)
            )
          )
          (2): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=256, bias=True)
              (1): Linear(in_features=256, out_features=256, bias=True)
              (2): Linear(in_features=256, out_features=4, bias=True)
            )
          )
          (3): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=256, bias=True)
              (1): Linear(in_features=256, out_features=256, bias=True)
              (2): Linear(in_features=256, out_features=4, bias=True)
            )
          )
          (4): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=256, bias=True)
              (1): Linear(in_features=256, out_features=256, bias=True)
              (2): Linear(in_features=256, out_features=4, bias=True)
            )
          )
          (5): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=256, bias=True)
              (1): Linear(in_features=256, out_features=256, bias=True)
              (2): Linear(in_features=256, out_features=4, bias=True)
            )
          )
          (6): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=256, bias=True)
              (1): Linear(in_features=256, out_features=256, bias=True)
              (2): Linear(in_features=256, out_features=4, bias=True)
            )
          )
          (7): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=256, bias=True)
              (1): Linear(in_features=256, out_features=256, bias=True)
              (2): Linear(in_features=256, out_features=4, bias=True)
            )
          )
          (8): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=256, bias=True)
              (1): Linear(in_features=256, out_features=256, bias=True)
              (2): Linear(in_features=256, out_features=4, bias=True)
            )
          )
        )
      )
      (head_box_embed_): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (head_class_embed_): Linear(in_features=256, out_features=2, bias=True)
      (head_bbox_embed): ModuleList(
        (0): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
        (1): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
        (2): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
      )
      (head_class_embed): ModuleList(
        (0): Linear(in_features=256, out_features=2, bias=True)
        (1): Linear(in_features=256, out_features=2, bias=True)
        (2): Linear(in_features=256, out_features=2, bias=True)
      )
      (_bbox_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (bbox_embed): ModuleList(
        (0): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
        (1): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
        (2): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
        (3): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
        (4): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
        (5): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
        (6): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
        (7): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
        (8): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
      )
      (ref_point_head): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=512, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 4.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks', 'boxes']
      weight_dict: {'loss_ce': 4.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_bbox': 5.0, 'loss_giou': 2.0, 'loss_ce_interm': 4.0, 'loss_mask_interm': 5.0, 'loss_dice_interm': 5.0, 'loss_bbox_interm': 5.0, 'loss_giou_interm': 2.0, 'loss_gaze': 1000, 'loss_direction': 10, 'loss_mask_energy': 1, 'loss_ce_head': 4.0, 'loss_bbox_head': 5.0, 'loss_giou_head': 2.0, 'loss_ce_dn': 4.0, 'loss_mask_dn': 5.0, 'loss_dice_dn': 5.0, 'loss_bbox_dn': 5.0, 'loss_giou_dn': 2.0, 'loss_ce_interm_dn': 4.0, 'loss_mask_interm_dn': 5.0, 'loss_dice_interm_dn': 5.0, 'loss_bbox_interm_dn': 5.0, 'loss_giou_interm_dn': 2.0, 'loss_gaze_dn': 1000, 'loss_direction_dn': 10, 'loss_mask_energy_dn': 1, 'loss_ce_head_dn': 4.0, 'loss_bbox_head_dn': 5.0, 'loss_giou_head_dn': 2.0, 'loss_ce_0': 4.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_bbox_0': 5.0, 'loss_giou_0': 2.0, 'loss_ce_interm_0': 4.0, 'loss_mask_interm_0': 5.0, 'loss_dice_interm_0': 5.0, 'loss_bbox_interm_0': 5.0, 'loss_giou_interm_0': 2.0, 'loss_gaze_0': 1000, 'loss_direction_0': 10, 'loss_mask_energy_0': 1, 'loss_ce_head_0': 4.0, 'loss_bbox_head_0': 5.0, 'loss_giou_head_0': 2.0, 'loss_ce_dn_0': 4.0, 'loss_mask_dn_0': 5.0, 'loss_dice_dn_0': 5.0, 'loss_bbox_dn_0': 5.0, 'loss_giou_dn_0': 2.0, 'loss_ce_interm_dn_0': 4.0, 'loss_mask_interm_dn_0': 5.0, 'loss_dice_interm_dn_0': 5.0, 'loss_bbox_interm_dn_0': 5.0, 'loss_giou_interm_dn_0': 2.0, 'loss_gaze_dn_0': 1000, 'loss_direction_dn_0': 10, 'loss_mask_energy_dn_0': 1, 'loss_ce_head_dn_0': 4.0, 'loss_bbox_head_dn_0': 5.0, 'loss_giou_head_dn_0': 2.0, 'loss_ce_1': 4.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_bbox_1': 5.0, 'loss_giou_1': 2.0, 'loss_ce_interm_1': 4.0, 'loss_mask_interm_1': 5.0, 'loss_dice_interm_1': 5.0, 'loss_bbox_interm_1': 5.0, 'loss_giou_interm_1': 2.0, 'loss_gaze_1': 1000, 'loss_direction_1': 10, 'loss_mask_energy_1': 1, 'loss_ce_head_1': 4.0, 'loss_bbox_head_1': 5.0, 'loss_giou_head_1': 2.0, 'loss_ce_dn_1': 4.0, 'loss_mask_dn_1': 5.0, 'loss_dice_dn_1': 5.0, 'loss_bbox_dn_1': 5.0, 'loss_giou_dn_1': 2.0, 'loss_ce_interm_dn_1': 4.0, 'loss_mask_interm_dn_1': 5.0, 'loss_dice_interm_dn_1': 5.0, 'loss_bbox_interm_dn_1': 5.0, 'loss_giou_interm_dn_1': 2.0, 'loss_gaze_dn_1': 1000, 'loss_direction_dn_1': 10, 'loss_mask_energy_dn_1': 1, 'loss_ce_head_dn_1': 4.0, 'loss_bbox_head_dn_1': 5.0, 'loss_giou_head_dn_1': 2.0, 'loss_ce_2': 4.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_bbox_2': 5.0, 'loss_giou_2': 2.0, 'loss_ce_interm_2': 4.0, 'loss_mask_interm_2': 5.0, 'loss_dice_interm_2': 5.0, 'loss_bbox_interm_2': 5.0, 'loss_giou_interm_2': 2.0, 'loss_gaze_2': 1000, 'loss_direction_2': 10, 'loss_mask_energy_2': 1, 'loss_ce_head_2': 4.0, 'loss_bbox_head_2': 5.0, 'loss_giou_head_2': 2.0, 'loss_ce_dn_2': 4.0, 'loss_mask_dn_2': 5.0, 'loss_dice_dn_2': 5.0, 'loss_bbox_dn_2': 5.0, 'loss_giou_dn_2': 2.0, 'loss_ce_interm_dn_2': 4.0, 'loss_mask_interm_dn_2': 5.0, 'loss_dice_interm_dn_2': 5.0, 'loss_bbox_interm_dn_2': 5.0, 'loss_giou_interm_dn_2': 2.0, 'loss_gaze_dn_2': 1000, 'loss_direction_dn_2': 10, 'loss_mask_energy_dn_2': 1, 'loss_ce_head_dn_2': 4.0, 'loss_bbox_head_dn_2': 5.0, 'loss_giou_head_dn_2': 2.0, 'loss_ce_3': 4.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_bbox_3': 5.0, 'loss_giou_3': 2.0, 'loss_ce_interm_3': 4.0, 'loss_mask_interm_3': 5.0, 'loss_dice_interm_3': 5.0, 'loss_bbox_interm_3': 5.0, 'loss_giou_interm_3': 2.0, 'loss_gaze_3': 1000, 'loss_direction_3': 10, 'loss_mask_energy_3': 1, 'loss_ce_head_3': 4.0, 'loss_bbox_head_3': 5.0, 'loss_giou_head_3': 2.0, 'loss_ce_dn_3': 4.0, 'loss_mask_dn_3': 5.0, 'loss_dice_dn_3': 5.0, 'loss_bbox_dn_3': 5.0, 'loss_giou_dn_3': 2.0, 'loss_ce_interm_dn_3': 4.0, 'loss_mask_interm_dn_3': 5.0, 'loss_dice_interm_dn_3': 5.0, 'loss_bbox_interm_dn_3': 5.0, 'loss_giou_interm_dn_3': 2.0, 'loss_gaze_dn_3': 1000, 'loss_direction_dn_3': 10, 'loss_mask_energy_dn_3': 1, 'loss_ce_head_dn_3': 4.0, 'loss_bbox_head_dn_3': 5.0, 'loss_giou_head_dn_3': 2.0, 'loss_ce_4': 4.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_bbox_4': 5.0, 'loss_giou_4': 2.0, 'loss_ce_interm_4': 4.0, 'loss_mask_interm_4': 5.0, 'loss_dice_interm_4': 5.0, 'loss_bbox_interm_4': 5.0, 'loss_giou_interm_4': 2.0, 'loss_gaze_4': 1000, 'loss_direction_4': 10, 'loss_mask_energy_4': 1, 'loss_ce_head_4': 4.0, 'loss_bbox_head_4': 5.0, 'loss_giou_head_4': 2.0, 'loss_ce_dn_4': 4.0, 'loss_mask_dn_4': 5.0, 'loss_dice_dn_4': 5.0, 'loss_bbox_dn_4': 5.0, 'loss_giou_dn_4': 2.0, 'loss_ce_interm_dn_4': 4.0, 'loss_mask_interm_dn_4': 5.0, 'loss_dice_interm_dn_4': 5.0, 'loss_bbox_interm_dn_4': 5.0, 'loss_giou_interm_dn_4': 2.0, 'loss_gaze_dn_4': 1000, 'loss_direction_dn_4': 10, 'loss_mask_energy_dn_4': 1, 'loss_ce_head_dn_4': 4.0, 'loss_bbox_head_dn_4': 5.0, 'loss_giou_head_dn_4': 2.0, 'loss_ce_5': 4.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_bbox_5': 5.0, 'loss_giou_5': 2.0, 'loss_ce_interm_5': 4.0, 'loss_mask_interm_5': 5.0, 'loss_dice_interm_5': 5.0, 'loss_bbox_interm_5': 5.0, 'loss_giou_interm_5': 2.0, 'loss_gaze_5': 1000, 'loss_direction_5': 10, 'loss_mask_energy_5': 1, 'loss_ce_head_5': 4.0, 'loss_bbox_head_5': 5.0, 'loss_giou_head_5': 2.0, 'loss_ce_dn_5': 4.0, 'loss_mask_dn_5': 5.0, 'loss_dice_dn_5': 5.0, 'loss_bbox_dn_5': 5.0, 'loss_giou_dn_5': 2.0, 'loss_ce_interm_dn_5': 4.0, 'loss_mask_interm_dn_5': 5.0, 'loss_dice_interm_dn_5': 5.0, 'loss_bbox_interm_dn_5': 5.0, 'loss_giou_interm_dn_5': 2.0, 'loss_gaze_dn_5': 1000, 'loss_direction_dn_5': 10, 'loss_mask_energy_dn_5': 1, 'loss_ce_head_dn_5': 4.0, 'loss_bbox_head_dn_5': 5.0, 'loss_giou_head_dn_5': 2.0, 'loss_ce_6': 4.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_bbox_6': 5.0, 'loss_giou_6': 2.0, 'loss_ce_interm_6': 4.0, 'loss_mask_interm_6': 5.0, 'loss_dice_interm_6': 5.0, 'loss_bbox_interm_6': 5.0, 'loss_giou_interm_6': 2.0, 'loss_gaze_6': 1000, 'loss_direction_6': 10, 'loss_mask_energy_6': 1, 'loss_ce_head_6': 4.0, 'loss_bbox_head_6': 5.0, 'loss_giou_head_6': 2.0, 'loss_ce_dn_6': 4.0, 'loss_mask_dn_6': 5.0, 'loss_dice_dn_6': 5.0, 'loss_bbox_dn_6': 5.0, 'loss_giou_dn_6': 2.0, 'loss_ce_interm_dn_6': 4.0, 'loss_mask_interm_dn_6': 5.0, 'loss_dice_interm_dn_6': 5.0, 'loss_bbox_interm_dn_6': 5.0, 'loss_giou_interm_dn_6': 2.0, 'loss_gaze_dn_6': 1000, 'loss_direction_dn_6': 10, 'loss_mask_energy_dn_6': 1, 'loss_ce_head_dn_6': 4.0, 'loss_bbox_head_dn_6': 5.0, 'loss_giou_head_dn_6': 2.0, 'loss_ce_7': 4.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_bbox_7': 5.0, 'loss_giou_7': 2.0, 'loss_ce_interm_7': 4.0, 'loss_mask_interm_7': 5.0, 'loss_dice_interm_7': 5.0, 'loss_bbox_interm_7': 5.0, 'loss_giou_interm_7': 2.0, 'loss_gaze_7': 1000, 'loss_direction_7': 10, 'loss_mask_energy_7': 1, 'loss_ce_head_7': 4.0, 'loss_bbox_head_7': 5.0, 'loss_giou_head_7': 2.0, 'loss_ce_dn_7': 4.0, 'loss_mask_dn_7': 5.0, 'loss_dice_dn_7': 5.0, 'loss_bbox_dn_7': 5.0, 'loss_giou_dn_7': 2.0, 'loss_ce_interm_dn_7': 4.0, 'loss_mask_interm_dn_7': 5.0, 'loss_dice_interm_dn_7': 5.0, 'loss_bbox_interm_dn_7': 5.0, 'loss_giou_interm_dn_7': 2.0, 'loss_gaze_dn_7': 1000, 'loss_direction_dn_7': 10, 'loss_mask_energy_dn_7': 1, 'loss_ce_head_dn_7': 4.0, 'loss_bbox_head_dn_7': 5.0, 'loss_giou_head_dn_7': 2.0, 'loss_ce_8': 4.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0, 'loss_bbox_8': 5.0, 'loss_giou_8': 2.0, 'loss_ce_interm_8': 4.0, 'loss_mask_interm_8': 5.0, 'loss_dice_interm_8': 5.0, 'loss_bbox_interm_8': 5.0, 'loss_giou_interm_8': 2.0, 'loss_gaze_8': 1000, 'loss_direction_8': 10, 'loss_mask_energy_8': 1, 'loss_ce_head_8': 4.0, 'loss_bbox_head_8': 5.0, 'loss_giou_head_8': 2.0, 'loss_ce_dn_8': 4.0, 'loss_mask_dn_8': 5.0, 'loss_dice_dn_8': 5.0, 'loss_bbox_dn_8': 5.0, 'loss_giou_dn_8': 2.0, 'loss_ce_interm_dn_8': 4.0, 'loss_mask_interm_dn_8': 5.0, 'loss_dice_interm_dn_8': 5.0, 'loss_bbox_interm_dn_8': 5.0, 'loss_giou_interm_dn_8': 2.0, 'loss_gaze_dn_8': 1000, 'loss_direction_dn_8': 10, 'loss_mask_energy_dn_8': 1, 'loss_ce_head_dn_8': 4.0, 'loss_bbox_head_dn_8': 5.0, 'loss_giou_head_dn_8': 2.0}
      num_classes: 24
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
  (head_proposal_align): RoIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
  (resnet_block): Resnet(
    (model): ResNet(
      (layer5_scene): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer5_face): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
    )
  )
  (relu): ReLU(inplace=True)
  (ps1): Pixel_shuffle1(
    (pixel_shuffle): Sequential(
      (0): PixelShuffle(upscale_factor=4)
      (1): Sequential(
        (conv): Conv2d(16, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): LeakyReLU(negative_slope=0.1)
      )
    )
  )
  (ps2): Pixel_shuffle(
    (pixel_shuffle): Sequential(
      (0): PixelShuffle(upscale_factor=2)
      (1): Sequential(
        (conv): Conv2d(128, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): LeakyReLU(negative_slope=0.1)
      )
    )
  )
  (ps3): Pixel_shuffle(
    (pixel_shuffle): Sequential(
      (0): PixelShuffle(upscale_factor=2)
      (1): Sequential(
        (conv): Conv2d(256, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): LeakyReLU(negative_slope=0.1)
      )
    )
  )
  (ps4): Pixel_shuffle(
    (pixel_shuffle): Sequential(
      (0): PixelShuffle(upscale_factor=2)
      (1): Sequential(
        (conv): Conv2d(512, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): LeakyReLU(negative_slope=0.1)
      )
    )
  )
  (head_conv_block): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (1): ReLU()
    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (3): ReLU()
    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (5): ReLU()
    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (7): ReLU()
    (8): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (9): ReLU()
  )
  (mask_feat_conv_block): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (2): ReLU()
    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (4): ReLU()
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)
  (direction_fc): Sequential(
    (0): Linear(in_features=2048, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=512, out_features=256, bias=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=256, out_features=2, bias=True)
    (5): Tanh()
  )
  (conv_face_scene): Conv2d(2560, 2048, kernel_size=(1, 1), stride=(1, 1))
  (attn): Linear(in_features=1808, out_features=49, bias=True)
  (compress_conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (compress_bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (compress_conv2): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (compress_bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv1): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2))
  (deconv_bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (totrans_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (totrans_conv_bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (query_embed): Embedding(225, 256)
  (transformer_layer): Transformer(
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.0, inplace=False)
          (dropout2): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (decoder): TransformerDecoder(
      (layers): ModuleList(
        (0): TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.0, inplace=False)
          (dropout2): Dropout(p=0.0, inplace=False)
          (dropout3): Dropout(p=0.0, inplace=False)
        )
      )
      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
  )
  (conv_trblock): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
  (trblock_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv2): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2))
  (deconv_bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv3): ConvTranspose2d(128, 1, kernel_size=(4, 4), stride=(2, 2))
  (deconv_bn3): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv4): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1))
)
[07/02 15:52:50] maskdino.data.dataset_mappers.coco_instance_new_baseline_dataset_mapper INFO: [COCOInstanceNewBaselineDatasetMapper] Full TransformGens used in training: [RandomFlip(), ResizeScale(min_scale=0.8, max_scale=1.0, target_height=224, target_width=224), FixedSizeCrop(crop_size=(224, 224)), RandomBrightness(intensity_min=0.5, intensity_max=1.5), RandomContrast(intensity_min=0.5, intensity_max=1.5), RandomSaturation(intensity_min=0, intensity_max=1.5)]
[07/02 15:52:55] d2.data.datasets.coco INFO: Loading datasets/coco/annotations/instances_train2017.json takes 5.44 seconds.
[07/02 15:52:56] d2.data.datasets.coco INFO: Loaded 3609 images in COCO format from datasets/coco/annotations/instances_train2017.json
[07/02 15:52:57] d2.data.build INFO: Removed 0 images with no usable annotations. 3609 images left.
[07/02 15:52:57] d2.data.build INFO: Distribution of instances among all 24 categories:
|   category    | #instances   |   category    | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|
| Kellogg Cor.. | 10677        |  Honey Stars  | 9875         |  Koko Krunch  | 9916         |
|     Fita      | 19290        |     Mamon     | 9924         |  Buttercake   | 19545        |
|     Wafer     | 3291         | Choco Crunc.. | 39469        |     iHop      | 9919         |
| Butterlicious | 20002        |    Pik-nik    | 9669         |   Pringles    | 16383        |
| Super Fruits  | 9801         | Locally Mango | 9848         |   Camomille   | 19174        |
|  Oishi Prawn  | 10041        | Kimchi Nood.. | 12956        |    Grahams    | 9903         |
|    Hansel     | 9938         |    Danisa     | 9572         | Chocolate C.. | 9755         |
|  Fresh Milk   | 13059        |  Bear brand   | 13559        |    Chuckie    | 23017        |
|               |              |               |              |               |              |
|     total     | 328583       |               |              |               |              |
[07/02 15:52:57] d2.data.build INFO: Using training sampler TrainingSampler
[07/02 15:52:57] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[07/02 15:52:57] d2.data.common INFO: Serializing 3609 elements to byte tensors and concatenating them all ...
[07/02 15:52:57] d2.data.common INFO: Serialized dataset takes 208.53 MiB
[07/02 15:52:58] d2.solver.build WARNING: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
[07/02 15:52:58] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[07/02 15:52:58] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /data1/jinyang/.torch/iopath_cache/detectron2/ImageNetPretrained/torchvision/R-50.pkl ...
[07/02 15:52:58] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[07/02 15:52:58] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[07/02 15:52:58] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
attn.{bias, weight}
compress_bn1.{bias, running_mean, running_var, weight}
compress_bn2.{bias, running_mean, running_var, weight}
compress_conv1.weight
compress_conv2.weight
conv4.{bias, weight}
conv_face_scene.{bias, weight}
conv_trblock.{bias, weight}
criterion.empty_weight
deconv1.{bias, weight}
deconv2.{bias, weight}
deconv3.{bias, weight}
deconv_bn1.{bias, running_mean, running_var, weight}
deconv_bn2.{bias, running_mean, running_var, weight}
deconv_bn3.{bias, running_mean, running_var, weight}
direction_fc.0.{bias, weight}
direction_fc.2.{bias, weight}
direction_fc.4.{bias, weight}
head_conv_block.0.weight
head_conv_block.2.weight
head_conv_block.4.weight
head_conv_block.6.weight
head_conv_block.8.weight
mask_feat_conv_block.0.weight
mask_feat_conv_block.3.weight
ps1.pixel_shuffle.1.bn.{bias, running_mean, running_var, weight}
ps1.pixel_shuffle.1.conv.weight
ps2.pixel_shuffle.1.bn.{bias, running_mean, running_var, weight}
ps2.pixel_shuffle.1.conv.weight
ps3.pixel_shuffle.1.bn.{bias, running_mean, running_var, weight}
ps3.pixel_shuffle.1.conv.weight
ps4.pixel_shuffle.1.bn.{bias, running_mean, running_var, weight}
ps4.pixel_shuffle.1.conv.weight
query_embed.weight
resnet_block.model.layer5_face.0.bn1.{bias, running_mean, running_var, weight}
resnet_block.model.layer5_face.0.bn2.{bias, running_mean, running_var, weight}
resnet_block.model.layer5_face.0.bn3.{bias, running_mean, running_var, weight}
resnet_block.model.layer5_face.0.conv1.weight
resnet_block.model.layer5_face.0.conv2.weight
resnet_block.model.layer5_face.0.conv3.weight
resnet_block.model.layer5_face.0.downsample.0.weight
resnet_block.model.layer5_face.0.downsample.1.{bias, running_mean, running_var, weight}
resnet_block.model.layer5_face.1.bn1.{bias, running_mean, running_var, weight}
resnet_block.model.layer5_face.1.bn2.{bias, running_mean, running_var, weight}
resnet_block.model.layer5_face.1.bn3.{bias, running_mean, running_var, weight}
resnet_block.model.layer5_face.1.conv1.weight
resnet_block.model.layer5_face.1.conv2.weight
resnet_block.model.layer5_face.1.conv3.weight
resnet_block.model.layer5_scene.0.bn1.{bias, running_mean, running_var, weight}
resnet_block.model.layer5_scene.0.bn2.{bias, running_mean, running_var, weight}
resnet_block.model.layer5_scene.0.bn3.{bias, running_mean, running_var, weight}
resnet_block.model.layer5_scene.0.conv1.weight
resnet_block.model.layer5_scene.0.conv2.weight
resnet_block.model.layer5_scene.0.conv3.weight
resnet_block.model.layer5_scene.0.downsample.0.weight
resnet_block.model.layer5_scene.0.downsample.1.{bias, running_mean, running_var, weight}
resnet_block.model.layer5_scene.1.bn1.{bias, running_mean, running_var, weight}
resnet_block.model.layer5_scene.1.bn2.{bias, running_mean, running_var, weight}
resnet_block.model.layer5_scene.1.bn3.{bias, running_mean, running_var, weight}
resnet_block.model.layer5_scene.1.conv1.weight
resnet_block.model.layer5_scene.1.conv2.weight
resnet_block.model.layer5_scene.1.conv3.weight
sem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}
sem_seg_head.pixel_decoder.adapter_1.weight
sem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}
sem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}
sem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}
sem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}
sem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}
sem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}
sem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}
sem_seg_head.pixel_decoder.layer_1.weight
sem_seg_head.pixel_decoder.mask_features.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}
sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}
sem_seg_head.pixel_decoder.transformer.level_embed
sem_seg_head.predictor._bbox_embed.layers.0.{bias, weight}
sem_seg_head.predictor._bbox_embed.layers.1.{bias, weight}
sem_seg_head.predictor._bbox_embed.layers.2.{bias, weight}
sem_seg_head.predictor.bbox_embed.0.layers.0.{bias, weight}
sem_seg_head.predictor.bbox_embed.0.layers.1.{bias, weight}
sem_seg_head.predictor.bbox_embed.0.layers.2.{bias, weight}
sem_seg_head.predictor.bbox_embed.1.layers.0.{bias, weight}
sem_seg_head.predictor.bbox_embed.1.layers.1.{bias, weight}
sem_seg_head.predictor.bbox_embed.1.layers.2.{bias, weight}
sem_seg_head.predictor.bbox_embed.2.layers.0.{bias, weight}
sem_seg_head.predictor.bbox_embed.2.layers.1.{bias, weight}
sem_seg_head.predictor.bbox_embed.2.layers.2.{bias, weight}
sem_seg_head.predictor.bbox_embed.3.layers.0.{bias, weight}
sem_seg_head.predictor.bbox_embed.3.layers.1.{bias, weight}
sem_seg_head.predictor.bbox_embed.3.layers.2.{bias, weight}
sem_seg_head.predictor.bbox_embed.4.layers.0.{bias, weight}
sem_seg_head.predictor.bbox_embed.4.layers.1.{bias, weight}
sem_seg_head.predictor.bbox_embed.4.layers.2.{bias, weight}
sem_seg_head.predictor.bbox_embed.5.layers.0.{bias, weight}
sem_seg_head.predictor.bbox_embed.5.layers.1.{bias, weight}
sem_seg_head.predictor.bbox_embed.5.layers.2.{bias, weight}
sem_seg_head.predictor.bbox_embed.6.layers.0.{bias, weight}
sem_seg_head.predictor.bbox_embed.6.layers.1.{bias, weight}
sem_seg_head.predictor.bbox_embed.6.layers.2.{bias, weight}
sem_seg_head.predictor.bbox_embed.7.layers.0.{bias, weight}
sem_seg_head.predictor.bbox_embed.7.layers.1.{bias, weight}
sem_seg_head.predictor.bbox_embed.7.layers.2.{bias, weight}
sem_seg_head.predictor.bbox_embed.8.layers.0.{bias, weight}
sem_seg_head.predictor.bbox_embed.8.layers.1.{bias, weight}
sem_seg_head.predictor.bbox_embed.8.layers.2.{bias, weight}
sem_seg_head.predictor.class_embed.{bias, weight}
sem_seg_head.predictor.decoder.bbox_embed.0.layers.0.{bias, weight}
sem_seg_head.predictor.decoder.bbox_embed.0.layers.1.{bias, weight}
sem_seg_head.predictor.decoder.bbox_embed.0.layers.2.{bias, weight}
sem_seg_head.predictor.decoder.bbox_embed.1.layers.0.{bias, weight}
sem_seg_head.predictor.decoder.bbox_embed.1.layers.1.{bias, weight}
sem_seg_head.predictor.decoder.bbox_embed.1.layers.2.{bias, weight}
sem_seg_head.predictor.decoder.bbox_embed.2.layers.0.{bias, weight}
sem_seg_head.predictor.decoder.bbox_embed.2.layers.1.{bias, weight}
sem_seg_head.predictor.decoder.bbox_embed.2.layers.2.{bias, weight}
sem_seg_head.predictor.decoder.bbox_embed.3.layers.0.{bias, weight}
sem_seg_head.predictor.decoder.bbox_embed.3.layers.1.{bias, weight}
sem_seg_head.predictor.decoder.bbox_embed.3.layers.2.{bias, weight}
sem_seg_head.predictor.decoder.bbox_embed.4.layers.0.{bias, weight}
sem_seg_head.predictor.decoder.bbox_embed.4.layers.1.{bias, weight}
sem_seg_head.predictor.decoder.bbox_embed.4.layers.2.{bias, weight}
sem_seg_head.predictor.decoder.bbox_embed.5.layers.0.{bias, weight}
sem_seg_head.predictor.decoder.bbox_embed.5.layers.1.{bias, weight}
sem_seg_head.predictor.decoder.bbox_embed.5.layers.2.{bias, weight}
sem_seg_head.predictor.decoder.bbox_embed.6.layers.0.{bias, weight}
sem_seg_head.predictor.decoder.bbox_embed.6.layers.1.{bias, weight}
sem_seg_head.predictor.decoder.bbox_embed.6.layers.2.{bias, weight}
sem_seg_head.predictor.decoder.bbox_embed.7.layers.0.{bias, weight}
sem_seg_head.predictor.decoder.bbox_embed.7.layers.1.{bias, weight}
sem_seg_head.predictor.decoder.bbox_embed.7.layers.2.{bias, weight}
sem_seg_head.predictor.decoder.bbox_embed.8.layers.0.{bias, weight}
sem_seg_head.predictor.decoder.bbox_embed.8.layers.1.{bias, weight}
sem_seg_head.predictor.decoder.bbox_embed.8.layers.2.{bias, weight}
sem_seg_head.predictor.decoder.layers.0.cross_attn.attention_weights.{bias, weight}
sem_seg_head.predictor.decoder.layers.0.cross_attn.output_proj.{bias, weight}
sem_seg_head.predictor.decoder.layers.0.cross_attn.sampling_offsets.{bias, weight}
sem_seg_head.predictor.decoder.layers.0.cross_attn.value_proj.{bias, weight}
sem_seg_head.predictor.decoder.layers.0.linear1.{bias, weight}
sem_seg_head.predictor.decoder.layers.0.linear2.{bias, weight}
sem_seg_head.predictor.decoder.layers.0.norm1.{bias, weight}
sem_seg_head.predictor.decoder.layers.0.norm2.{bias, weight}
sem_seg_head.predictor.decoder.layers.0.norm3.{bias, weight}
sem_seg_head.predictor.decoder.layers.0.self_attn.out_proj.{bias, weight}
sem_seg_head.predictor.decoder.layers.0.self_attn.{in_proj_bias, in_proj_weight}
sem_seg_head.predictor.decoder.layers.1.cross_attn.attention_weights.{bias, weight}
sem_seg_head.predictor.decoder.layers.1.cross_attn.output_proj.{bias, weight}
sem_seg_head.predictor.decoder.layers.1.cross_attn.sampling_offsets.{bias, weight}
sem_seg_head.predictor.decoder.layers.1.cross_attn.value_proj.{bias, weight}
sem_seg_head.predictor.decoder.layers.1.linear1.{bias, weight}
sem_seg_head.predictor.decoder.layers.1.linear2.{bias, weight}
sem_seg_head.predictor.decoder.layers.1.norm1.{bias, weight}
sem_seg_head.predictor.decoder.layers.1.norm2.{bias, weight}
sem_seg_head.predictor.decoder.layers.1.norm3.{bias, weight}
sem_seg_head.predictor.decoder.layers.1.self_attn.out_proj.{bias, weight}
sem_seg_head.predictor.decoder.layers.1.self_attn.{in_proj_bias, in_proj_weight}
sem_seg_head.predictor.decoder.layers.2.cross_attn.attention_weights.{bias, weight}
sem_seg_head.predictor.decoder.layers.2.cross_attn.output_proj.{bias, weight}
sem_seg_head.predictor.decoder.layers.2.cross_attn.sampling_offsets.{bias, weight}
sem_seg_head.predictor.decoder.layers.2.cross_attn.value_proj.{bias, weight}
sem_seg_head.predictor.decoder.layers.2.linear1.{bias, weight}
sem_seg_head.predictor.decoder.layers.2.linear2.{bias, weight}
sem_seg_head.predictor.decoder.layers.2.norm1.{bias, weight}
sem_seg_head.predictor.decoder.layers.2.norm2.{bias, weight}
sem_seg_head.predictor.decoder.layers.2.norm3.{bias, weight}
sem_seg_head.predictor.decoder.layers.2.self_attn.out_proj.{bias, weight}
sem_seg_head.predictor.decoder.layers.2.self_attn.{in_proj_bias, in_proj_weight}
sem_seg_head.predictor.decoder.layers.3.cross_attn.attention_weights.{bias, weight}
sem_seg_head.predictor.decoder.layers.3.cross_attn.output_proj.{bias, weight}
sem_seg_head.predictor.decoder.layers.3.cross_attn.sampling_offsets.{bias, weight}
sem_seg_head.predictor.decoder.layers.3.cross_attn.value_proj.{bias, weight}
sem_seg_head.predictor.decoder.layers.3.linear1.{bias, weight}
sem_seg_head.predictor.decoder.layers.3.linear2.{bias, weight}
sem_seg_head.predictor.decoder.layers.3.norm1.{bias, weight}
sem_seg_head.predictor.decoder.layers.3.norm2.{bias, weight}
sem_seg_head.predictor.decoder.layers.3.norm3.{bias, weight}
sem_seg_head.predictor.decoder.layers.3.self_attn.out_proj.{bias, weight}
sem_seg_head.predictor.decoder.layers.3.self_attn.{in_proj_bias, in_proj_weight}
sem_seg_head.predictor.decoder.layers.4.cross_attn.attention_weights.{bias, weight}
sem_seg_head.predictor.decoder.layers.4.cross_attn.output_proj.{bias, weight}
sem_seg_head.predictor.decoder.layers.4.cross_attn.sampling_offsets.{bias, weight}
sem_seg_head.predictor.decoder.layers.4.cross_attn.value_proj.{bias, weight}
sem_seg_head.predictor.decoder.layers.4.linear1.{bias, weight}
sem_seg_head.predictor.decoder.layers.4.linear2.{bias, weight}
sem_seg_head.predictor.decoder.layers.4.norm1.{bias, weight}
sem_seg_head.predictor.decoder.layers.4.norm2.{bias, weight}
sem_seg_head.predictor.decoder.layers.4.norm3.{bias, weight}
sem_seg_head.predictor.decoder.layers.4.self_attn.out_proj.{bias, weight}
sem_seg_head.predictor.decoder.layers.4.self_attn.{in_proj_bias, in_proj_weight}
sem_seg_head.predictor.decoder.layers.5.cross_attn.attention_weights.{bias, weight}
sem_seg_head.predictor.decoder.layers.5.cross_attn.output_proj.{bias, weight}
sem_seg_head.predictor.decoder.layers.5.cross_attn.sampling_offsets.{bias, weight}
sem_seg_head.predictor.decoder.layers.5.cross_attn.value_proj.{bias, weight}
sem_seg_head.predictor.decoder.layers.5.linear1.{bias, weight}
sem_seg_head.predictor.decoder.layers.5.linear2.{bias, weight}
sem_seg_head.predictor.decoder.layers.5.norm1.{bias, weight}
sem_seg_head.predictor.decoder.layers.5.norm2.{bias, weight}
sem_seg_head.predictor.decoder.layers.5.norm3.{bias, weight}
sem_seg_head.predictor.decoder.layers.5.self_attn.out_proj.{bias, weight}
sem_seg_head.predictor.decoder.layers.5.self_attn.{in_proj_bias, in_proj_weight}
sem_seg_head.predictor.decoder.layers.6.cross_attn.attention_weights.{bias, weight}
sem_seg_head.predictor.decoder.layers.6.cross_attn.output_proj.{bias, weight}
sem_seg_head.predictor.decoder.layers.6.cross_attn.sampling_offsets.{bias, weight}
sem_seg_head.predictor.decoder.layers.6.cross_attn.value_proj.{bias, weight}
sem_seg_head.predictor.decoder.layers.6.linear1.{bias, weight}
sem_seg_head.predictor.decoder.layers.6.linear2.{bias, weight}
sem_seg_head.predictor.decoder.layers.6.norm1.{bias, weight}
sem_seg_head.predictor.decoder.layers.6.norm2.{bias, weight}
sem_seg_head.predictor.decoder.layers.6.norm3.{bias, weight}
sem_seg_head.predictor.decoder.layers.6.self_attn.out_proj.{bias, weight}
sem_seg_head.predictor.decoder.layers.6.self_attn.{in_proj_bias, in_proj_weight}
sem_seg_head.predictor.decoder.layers.7.cross_attn.attention_weights.{bias, weight}
sem_seg_head.predictor.decoder.layers.7.cross_attn.output_proj.{bias, weight}
sem_seg_head.predictor.decoder.layers.7.cross_attn.sampling_offsets.{bias, weight}
sem_seg_head.predictor.decoder.layers.7.cross_attn.value_proj.{bias, weight}
sem_seg_head.predictor.decoder.layers.7.linear1.{bias, weight}
sem_seg_head.predictor.decoder.layers.7.linear2.{bias, weight}
sem_seg_head.predictor.decoder.layers.7.norm1.{bias, weight}
sem_seg_head.predictor.decoder.layers.7.norm2.{bias, weight}
sem_seg_head.predictor.decoder.layers.7.norm3.{bias, weight}
sem_seg_head.predictor.decoder.layers.7.self_attn.out_proj.{bias, weight}
sem_seg_head.predictor.decoder.layers.7.self_attn.{in_proj_bias, in_proj_weight}
sem_seg_head.predictor.decoder.layers.8.cross_attn.attention_weights.{bias, weight}
sem_seg_head.predictor.decoder.layers.8.cross_attn.output_proj.{bias, weight}
sem_seg_head.predictor.decoder.layers.8.cross_attn.sampling_offsets.{bias, weight}
sem_seg_head.predictor.decoder.layers.8.cross_attn.value_proj.{bias, weight}
sem_seg_head.predictor.decoder.layers.8.linear1.{bias, weight}
sem_seg_head.predictor.decoder.layers.8.linear2.{bias, weight}
sem_seg_head.predictor.decoder.layers.8.norm1.{bias, weight}
sem_seg_head.predictor.decoder.layers.8.norm2.{bias, weight}
sem_seg_head.predictor.decoder.layers.8.norm3.{bias, weight}
sem_seg_head.predictor.decoder.layers.8.self_attn.out_proj.{bias, weight}
sem_seg_head.predictor.decoder.layers.8.self_attn.{in_proj_bias, in_proj_weight}
sem_seg_head.predictor.decoder.norm.{bias, weight}
sem_seg_head.predictor.decoder.ref_point_head.layers.0.{bias, weight}
sem_seg_head.predictor.decoder.ref_point_head.layers.1.{bias, weight}
sem_seg_head.predictor.decoder_head.layers.0.cross_attn.attention_weights.{bias, weight}
sem_seg_head.predictor.decoder_head.layers.0.cross_attn.output_proj.{bias, weight}
sem_seg_head.predictor.decoder_head.layers.0.cross_attn.sampling_offsets.{bias, weight}
sem_seg_head.predictor.decoder_head.layers.0.cross_attn.value_proj.{bias, weight}
sem_seg_head.predictor.decoder_head.layers.0.linear1.{bias, weight}
sem_seg_head.predictor.decoder_head.layers.0.linear2.{bias, weight}
sem_seg_head.predictor.decoder_head.layers.0.norm1.{bias, weight}
sem_seg_head.predictor.decoder_head.layers.0.norm2.{bias, weight}
sem_seg_head.predictor.decoder_head.layers.0.norm3.{bias, weight}
sem_seg_head.predictor.decoder_head.layers.0.self_attn.out_proj.{bias, weight}
sem_seg_head.predictor.decoder_head.layers.0.self_attn.{in_proj_bias, in_proj_weight}
sem_seg_head.predictor.decoder_head.layers.1.cross_attn.attention_weights.{bias, weight}
sem_seg_head.predictor.decoder_head.layers.1.cross_attn.output_proj.{bias, weight}
sem_seg_head.predictor.decoder_head.layers.1.cross_attn.sampling_offsets.{bias, weight}
sem_seg_head.predictor.decoder_head.layers.1.cross_attn.value_proj.{bias, weight}
sem_seg_head.predictor.decoder_head.layers.1.linear1.{bias, weight}
sem_seg_head.predictor.decoder_head.layers.1.linear2.{bias, weight}
sem_seg_head.predictor.decoder_head.layers.1.norm1.{bias, weight}
sem_seg_head.predictor.decoder_head.layers.1.norm2.{bias, weight}
sem_seg_head.predictor.decoder_head.layers.1.norm3.{bias, weight}
sem_seg_head.predictor.decoder_head.layers.1.self_attn.out_proj.{bias, weight}
sem_seg_head.predictor.decoder_head.layers.1.self_attn.{in_proj_bias, in_proj_weight}
sem_seg_head.predictor.decoder_head.layers.2.cross_attn.attention_weights.{bias, weight}
sem_seg_head.predictor.decoder_head.layers.2.cross_attn.output_proj.{bias, weight}
sem_seg_head.predictor.decoder_head.layers.2.cross_attn.sampling_offsets.{bias, weight}
sem_seg_head.predictor.decoder_head.layers.2.cross_attn.value_proj.{bias, weight}
sem_seg_head.predictor.decoder_head.layers.2.linear1.{bias, weight}
sem_seg_head.predictor.decoder_head.layers.2.linear2.{bias, weight}
sem_seg_head.predictor.decoder_head.layers.2.norm1.{bias, weight}
sem_seg_head.predictor.decoder_head.layers.2.norm2.{bias, weight}
sem_seg_head.predictor.decoder_head.layers.2.norm3.{bias, weight}
sem_seg_head.predictor.decoder_head.layers.2.self_attn.out_proj.{bias, weight}
sem_seg_head.predictor.decoder_head.layers.2.self_attn.{in_proj_bias, in_proj_weight}
sem_seg_head.predictor.decoder_norm.{bias, weight}
sem_seg_head.predictor.enc_output.{bias, weight}
sem_seg_head.predictor.enc_output_norm.{bias, weight}
sem_seg_head.predictor.head_bbox_embed.0.layers.0.{bias, weight}
sem_seg_head.predictor.head_bbox_embed.0.layers.1.{bias, weight}
sem_seg_head.predictor.head_bbox_embed.0.layers.2.{bias, weight}
sem_seg_head.predictor.head_bbox_embed.1.layers.0.{bias, weight}
sem_seg_head.predictor.head_bbox_embed.1.layers.1.{bias, weight}
sem_seg_head.predictor.head_bbox_embed.1.layers.2.{bias, weight}
sem_seg_head.predictor.head_bbox_embed.2.layers.0.{bias, weight}
sem_seg_head.predictor.head_bbox_embed.2.layers.1.{bias, weight}
sem_seg_head.predictor.head_bbox_embed.2.layers.2.{bias, weight}
sem_seg_head.predictor.head_box_embed_.layers.0.{bias, weight}
sem_seg_head.predictor.head_box_embed_.layers.1.{bias, weight}
sem_seg_head.predictor.head_box_embed_.layers.2.{bias, weight}
sem_seg_head.predictor.head_class_embed.0.{bias, weight}
sem_seg_head.predictor.head_class_embed.1.{bias, weight}
sem_seg_head.predictor.head_class_embed.2.{bias, weight}
sem_seg_head.predictor.head_class_embed_.{bias, weight}
sem_seg_head.predictor.label_enc.weight
sem_seg_head.predictor.mask_embed.layers.0.{bias, weight}
sem_seg_head.predictor.mask_embed.layers.1.{bias, weight}
sem_seg_head.predictor.mask_embed.layers.2.{bias, weight}
sem_seg_head.predictor.query_embed_head.weight
sem_seg_head.predictor.ref_point_head.layers.0.{bias, weight}
sem_seg_head.predictor.ref_point_head.layers.1.{bias, weight}
sem_seg_head.predictor.reference_points_head.{bias, weight}
totrans_conv.weight
totrans_conv_bn1.{bias, running_mean, running_var, weight}
transformer_layer.decoder.layers.0.linear1.{bias, weight}
transformer_layer.decoder.layers.0.linear2.{bias, weight}
transformer_layer.decoder.layers.0.multihead_attn.out_proj.{bias, weight}
transformer_layer.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}
transformer_layer.decoder.layers.0.norm1.{bias, weight}
transformer_layer.decoder.layers.0.norm2.{bias, weight}
transformer_layer.decoder.layers.0.norm3.{bias, weight}
transformer_layer.decoder.layers.0.self_attn.out_proj.{bias, weight}
transformer_layer.decoder.layers.0.self_attn.{in_proj_bias, in_proj_weight}
transformer_layer.decoder.norm.{bias, weight}
transformer_layer.encoder.layers.0.linear1.{bias, weight}
transformer_layer.encoder.layers.0.linear2.{bias, weight}
transformer_layer.encoder.layers.0.norm1.{bias, weight}
transformer_layer.encoder.layers.0.norm2.{bias, weight}
transformer_layer.encoder.layers.0.self_attn.out_proj.{bias, weight}
transformer_layer.encoder.layers.0.self_attn.{in_proj_bias, in_proj_weight}
trblock_bn.{bias, running_mean, running_var, weight}
[07/02 15:52:58] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  stem.fc.{bias, weight}
[07/02 15:52:58] d2.engine.train_loop INFO: Starting training from iteration 0
[07/02 15:53:09] d2.data.datasets.coco INFO: Loading datasets/coco/annotations/instances_val2017.json takes 1.82 seconds.
[07/02 15:53:09] d2.data.datasets.coco INFO: Loaded 904 images in COCO format from datasets/coco/annotations/instances_val2017.json
[07/02 15:53:09] d2.data.build INFO: Distribution of instances among all 24 categories:
|   category    | #instances   |   category    | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|
| Kellogg Cor.. | 2638         |  Honey Stars  | 2479         |  Koko Krunch  | 2439         |
|     Fita      | 4972         |     Mamon     | 2537         |  Buttercake   | 4949         |
|     Wafer     | 818          | Choco Crunc.. | 9863         |     iHop      | 2599         |
| Butterlicious | 5060         |    Pik-nik    | 2491         |   Pringles    | 4242         |
| Super Fruits  | 2414         | Locally Mango | 2342         |   Camomille   | 4749         |
|  Oishi Prawn  | 2587         | Kimchi Nood.. | 3082         |    Grahams    | 2525         |
|    Hansel     | 2487         |    Danisa     | 2513         | Chocolate C.. | 2466         |
|  Fresh Milk   | 3267         |  Bear brand   | 3347         |    Chuckie    | 5710         |
|               |              |               |              |               |              |
|     total     | 82576        |               |              |               |              |
[07/02 15:53:09] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[07/02 15:53:09] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[07/02 15:53:09] d2.data.common INFO: Serializing 904 elements to byte tensors and concatenating them all ...
[07/02 15:53:09] d2.data.common INFO: Serialized dataset takes 51.43 MiB
[07/02 15:53:11] d2.evaluation.evaluator INFO: Start inference on 904 batches
[07/02 15:53:17] d2.evaluation.evaluator INFO: Inference done 11/904. Dataloading: 0.0010 s/iter. Inference: 0.0711 s/iter. Eval: 0.4254 s/iter. Total: 0.4975 s/iter. ETA=0:07:24
[07/02 15:53:20] d2.engine.hooks INFO: Overall training speed: 15 iterations in 0:00:07 (0.4980 s / it)
[07/02 15:53:20] d2.engine.hooks INFO: Total training time: 0:00:20 (0:00:13 on hooks)
[07/02 15:53:20] d2.utils.events INFO:  eta: 23:30:28  iter: 17  total_loss: 4386  loss_ce: 49.83  loss_mask: 3.668  loss_dice: 4.971  loss_bbox: 11.14  loss_giou: 1.995  loss_ce_head: 583.7  loss_bbox_head: 1.149  loss_giou_head: 0.6955  loss_gaze: 1450  loss_direction: 10.46  loss_mask_energy: 2.11  loss_ce_dn: 16.26  loss_mask_dn: 3.615  loss_dice_dn: 4.974  loss_bbox_dn: 0.2063  loss_giou_dn: 0.8581  loss_ce_head_0: 586.1  loss_bbox_head_0: 0.9849  loss_giou_head_0: 0.6342  loss_ce_head_1: 612.9  loss_bbox_head_1: 1.127  loss_giou_head_1: 0.673  loss_ce_0: 51.51  loss_mask_0: 2.383  loss_dice_0: 4.974  loss_bbox_0: 11.15  loss_giou_0: 1.995  loss_ce_dn_0: 17.6  loss_mask_dn_0: 3.67  loss_dice_dn_0: 4.973  loss_bbox_dn_0: 0.2063  loss_giou_dn_0: 0.8531  loss_ce_1: 49.36  loss_mask_1: 3.452  loss_dice_1: 4.973  loss_bbox_1: 11.15  loss_giou_1: 1.995  loss_ce_dn_1: 16.43  loss_mask_dn_1: 4.141  loss_dice_dn_1: 4.973  loss_bbox_dn_1: 0.2063  loss_giou_dn_1: 0.8531  loss_ce_2: 59.76  loss_mask_2: 4.121  loss_dice_2: 4.973  loss_bbox_2: 11.15  loss_giou_2: 1.995  loss_ce_dn_2: 19.98  loss_mask_dn_2: 5.171  loss_dice_dn_2: 4.973  loss_bbox_dn_2: 0.2063  loss_giou_dn_2: 0.8531  loss_ce_3: 66.56  loss_mask_3: 3.494  loss_dice_3: 4.973  loss_bbox_3: 11.15  loss_giou_3: 1.995  loss_ce_dn_3: 19.98  loss_mask_dn_3: 3.941  loss_dice_dn_3: 4.973  loss_bbox_dn_3: 0.2063  loss_giou_dn_3: 0.8532  loss_ce_4: 58.61  loss_mask_4: 3.328  loss_dice_4: 4.975  loss_bbox_4: 11.15  loss_giou_4: 1.995  loss_ce_dn_4: 17.35  loss_mask_dn_4: 3.477  loss_dice_dn_4: 4.974  loss_bbox_dn_4: 0.2063  loss_giou_dn_4: 0.8545  loss_ce_5: 73.02  loss_mask_5: 3.251  loss_dice_5: 4.975  loss_bbox_5: 11.14  loss_giou_5: 1.995  loss_ce_dn_5: 22.18  loss_mask_dn_5: 3.397  loss_dice_dn_5: 4.972  loss_bbox_dn_5: 0.2063  loss_giou_dn_5: 0.8558  loss_ce_6: 54.13  loss_mask_6: 3.765  loss_dice_6: 4.972  loss_bbox_6: 11.14  loss_giou_6: 1.995  loss_ce_dn_6: 15.9  loss_mask_dn_6: 3.82  loss_dice_dn_6: 4.972  loss_bbox_dn_6: 0.2063  loss_giou_dn_6: 0.8574  loss_ce_7: 52.71  loss_mask_7: 3.638  loss_dice_7: 4.972  loss_bbox_7: 11.14  loss_giou_7: 1.995  loss_ce_dn_7: 15.3  loss_mask_dn_7: 3.92  loss_dice_dn_7: 4.971  loss_bbox_dn_7: 0.2063  loss_giou_dn_7: 0.8581  loss_ce_8: 51.98  loss_mask_8: 4.358  loss_dice_8: 4.972  loss_bbox_8: 11.14  loss_giou_8: 1.995  loss_ce_dn_8: 15.72  loss_mask_dn_8: 4.856  loss_dice_dn_8: 4.972  loss_bbox_dn_8: 0.2063  loss_giou_dn_8: 0.8581  loss_ce_interm: 52.26  loss_mask_interm: 2.515  loss_dice_interm: 4.977  loss_bbox_interm: 1.263  loss_giou_interm: 2.547    time: 0.4669  last_time: 0.4649  data_time: 0.0339  last_data_time: 0.0318   lr: 0.0001  max_mem: 7767M
